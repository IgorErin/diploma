% !TeX spellcheck = ru_RU
% !TEX root = vkr.tex

\section{Система бенчмарков}

В качестве системы бенчмарков был создан проект \verb|tokiobench|\footnote{\href{https://github.com/IgorErin/tokiobench}{Репозиторий} проект tokiobench (Дата обращения: 4.1.2025)}, где предполагалось реализовать сценарии интересные для потребителей, сбор метрик и визуализацию полученных данных в виде графиков.

\subsection{Поиск сценариев}

При общении с командой \verb|TATLIN.BACKUP| был выделен интересующий их сценарий для измерения проиводительности. А именно:

\begin{itemize}
    \item Замыкания акторы --- замыкания, в цикле ожидающие асинхронные события
    \item Замыкания производители --- замыкания, отправляющие на исполнение множество замыканий акторов
\end{itemize}

Инженерам из \verb|TATLIN.BACKUP| интересно было исследовать производительность такого бенчмарка при следующих параметрах:

\begin{itemize}
    \item Тысяча листовых замыканий акторов
    \item Тысяча итераций исполнения акторов
    \item От десяти до ста замыканий производителей
\end{itemize}

\subsection{Реализация бенчмарков}

Измерение производительности в данном случае предполагает измерение пропускной способности рантайма, что подразумевает измерение времени необходимое этому рантайму для исполнения фиксированного количества задач. Однако, для этого необходимо определить, когда все задачи были исполнены. Публичный интерфейс \verb|tokio| не позволяет получить информацию об этом, так как число необходимых к исполнению задач известно лишь пользователю. То есть нужно иметь какую-то синхронизацию, блокировать поток бенчмарка в ожидании конца обработки специфицированных рантайму задач. В бенчмарках \verb|tokio| делают это следующими способами:

\begin{itemize}
    \item Коллекционирует хендлеры, как представлено на листинге \ref{listing:bench:tokio:remote} и последовательно ожидают их в цикле с помощью метода \verb|block_on|
    \item Создают атомарную переменную с значением равным количеству задач и в каждой листовой задаче уменьшают ее значение на единицу. Задача, которая получила ноль в результате операции атомарного декремента, посылает сигнал с помощью блокирующего канала в главный поток, тем самым разблокирует его, как представлено на листинге \ref{listing:bench:tokio:atom}
\end{itemize}

\begin{listing}[H]
    \begin{minted}{rust}
let (tx, rx) = mpsc::sync_channel(1);
let rem = Arc::new(AtomicUsize::new(NUM_SPAWN));
rt.block_on(async {
    for _ in 0..NUM_SPAWN {
        let tx = tx.clone();
        let rem = rem.clone();
        tokio::spawn(async move {
            if 1 == rem.fetch_sub(1, Relaxed) {
                tx.send(()); // отправление сигнала
            }
        });
    }
    rx.recv(); // блокирующее ожидание сигнала
});
    \end{minted}

    \caption{Атомарная синхронизация в бенчмарках tokio}
    \label{listing:bench:tokio:atom}
\end{listing}

Такой дизайн имеет несколько явных недостатков:

\begin{itemize}
    \item Атомарное чтение и запись из множества исполняемых разными потоками задач скорее позволяет измерять производительность системы памяти физической машины, нежели взаимодействия структур рантайма
    \item Ожидание исполнения в методе \verb|block_on| чревато неточным измерением из-за текущей реализации\footnote{\href{https://github.com/bheisler/criterion.rs/issues/819}{Проблема} измерения производительности асинхронных функций (Дата обращения: 4.1.2025)}
\end{itemize}

Эти методы были улучшены:

\begin{itemize}
    \item Атомарные переменная была заменена иерархией заранее аллоцированных переиспользуемых от итерации к итерации буферами коллекционирующими хендлеры задач
    \item Ожидание хендлеров задач перенесено в отдельную задачу, которая сообщает о завершении обработки с помощью блокирующего канала
\end{itemize}

Накладные расходы вызванные использованием блокирующего канала так же были приняты во внимание, поэтому, исключительно для проверки, была создана реализация использующая спинлок: фиксирующий исполнение и сигнализирующий поток пишет значение в атомарную переменную --- поток бенчмарка ожидает этого в цикле, на листинге \ref{listing:bench:tokiobench:spinlock} приведен псевдокод.

\begin{listing}[H]
    \begin{minted}{rust}
tokio::spawn(async move {
    for handle in handles {
        handle.await; // ожидание всех задач
    }
    task_end.store(true, Release); // отправка сигнала
});
while !end.load(Acquire) {
    std::hint::spin_loop() // ожидания сигнала
}
    \end{minted}
    \caption{Ожидание исполнения с помощью спинлока}
    \label{listing:bench:tokiobench:spinlock}
\end{listing}

\subsection{Реализация модели}

Сценарий был реализован следующим образом:

\begin{itemize}
    \item Первая tokio задача создает необходимое количество производителей, ожидает коллекцию их \verb|JoinHandle|, после чего оповещает поток бенчмарка об оконачнии обработки асинхронных задач с помощью блокирующего канала.
    \item Каждая задача производитель создает необходимое количество листовых задач и асинхронно ожидает коллекцию их \verb|JoinHandle|.
    \item Каждая листовая задача совершает необходимое количество \verb|yied_now| в цикле.
\end{itemize}

Констаанты были окружены не прозрачной для компилятора функцией, дабы избежать нереалистичных оптимизаций.
